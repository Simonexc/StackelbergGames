{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4250c661131d0c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T22:19:38.718477Z",
     "start_time": "2025-08-01T22:19:36.346Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import importlib\n",
    "from config import Player, EnvConfig\n",
    "from environments.flipit_utils import Action, ActionTargetPair, PlayerTargetPair\n",
    "from environments.poachers_renderer import Renderer\n",
    "import environments.poachers\n",
    "environments.poachers = importlib.reload(environments.poachers)\n",
    "import torch\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from torchrl.envs import Compose, TransformedEnv, RewardSum, Stack\n",
    "\n",
    "NUM_NODES = 20\n",
    "NUM_STEPS = 40\n",
    "SEED = 41\n",
    "\n",
    "config = EnvConfig(\n",
    "    num_nodes=NUM_NODES,\n",
    "    num_steps=NUM_STEPS,\n",
    "    seed=SEED,\n",
    "    env_name=\"poachers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922df165b7a6eead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T22:19:38.725483Z",
     "start_time": "2025-08-01T22:19:38.719550Z"
    }
   },
   "outputs": [],
   "source": [
    "env_map = environments.poachers.PoachersMap(config, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9032c089ecb33506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T22:19:39.187561Z",
     "start_time": "2025-08-01T22:19:38.726494Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid action detected: tensor([4, 5], dtype=torch.int32). Cannot prepare node 12.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m env = environments.poachers.PoachersEnv(config, env_map, \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mcheck_env_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m out = env.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/.venv/lib/python3.13/site-packages/torchrl/envs/utils.py:757\u001b[39m, in \u001b[36mcheck_env_specs\u001b[39m\u001b[34m(env, return_contiguous, check_dtype, seed, tensordict, break_when_any_done)\u001b[39m\n\u001b[32m    755\u001b[39m     fake_tensordict = fake_tensordict.expand(shape)\n\u001b[32m    756\u001b[39m     tensordict = tensordict.expand(shape)\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m real_tensordict = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_contiguous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_reset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_contiguous:\n\u001b[32m    766\u001b[39m     fake_tensordict = fake_tensordict.unsqueeze(real_tensordict.batch_dims - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/.venv/lib/python3.13/site-packages/torchrl/envs/common.py:3294\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3284\u001b[39m kwargs = {\n\u001b[32m   3285\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtensordict\u001b[39m\u001b[33m\"\u001b[39m: tensordict,\n\u001b[32m   3286\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mauto_cast_to_device\u001b[39m\u001b[33m\"\u001b[39m: auto_cast_to_device,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3291\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: callback,\n\u001b[32m   3292\u001b[39m }\n\u001b[32m   3293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m break_when_any_done \u001b[38;5;129;01mor\u001b[39;00m break_when_all_done:\n\u001b[32m-> \u001b[39m\u001b[32m3294\u001b[39m     tensordicts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rollout_stop_early\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbreak_when_all_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbreak_when_all_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3297\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3299\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3300\u001b[39m     tensordicts = \u001b[38;5;28mself\u001b[39m._rollout_nonstop(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/.venv/lib/python3.13/site-packages/torchrl/envs/common.py:3435\u001b[39m, in \u001b[36mEnvBase._rollout_stop_early\u001b[39m\u001b[34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[39m\n\u001b[32m   3433\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3434\u001b[39m         tensordict.clear_device_()\n\u001b[32m-> \u001b[39m\u001b[32m3435\u001b[39m tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3436\u001b[39m td_append = tensordict.copy()\n\u001b[32m   3437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m break_when_all_done:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/.venv/lib/python3.13/site-packages/torchrl/envs/common.py:2031\u001b[39m, in \u001b[36mEnvBase.step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   2028\u001b[39m next_preset = tensordict.get(\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2031\u001b[39m     next_tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2032\u001b[39m     next_tensordict = \u001b[38;5;28mself\u001b[39m._step_proc_data(next_tensordict)\n\u001b[32m   2033\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2034\u001b[39m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[32m   2035\u001b[39m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[32m   2036\u001b[39m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/src/environments/base_env.py:276\u001b[39m, in \u001b[36mEnvironmentBase._step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    273\u001b[39m is_truncated = torch.zeros((\u001b[32m1\u001b[39m,), dtype=torch.bool, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    274\u001b[39m is_terminated = torch.zeros((\u001b[32m1\u001b[39m,), dtype=torch.bool, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_impl_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_truncated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_terminated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28mself\u001b[39m.step_count += \u001b[32m1\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.step_count >= \u001b[38;5;28mself\u001b[39m.num_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/StackelbergGames/src/environments/poachers.py:314\u001b[39m, in \u001b[36mPoachersEnv._impl_step\u001b[39m\u001b[34m(self, tensordict, rewards, is_truncated, is_terminated)\u001b[39m\n\u001b[32m    312\u001b[39m         rewards[prepare_mask] += \u001b[38;5;28mself\u001b[39m.map.x[attackers_node, \u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Upgrade cost\u001b[39;00m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid action detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Cannot prepare node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattackers_node\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# Collect\u001b[39;00m\n\u001b[32m    317\u001b[39m collect_mask = actions == \u001b[32m6\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Invalid action detected: tensor([4, 5], dtype=torch.int32). Cannot prepare node 12."
     ]
    }
   ],
   "source": [
    "env = environments.poachers.PoachersEnv(config, env_map, \"cpu\")\n",
    "\n",
    "check_env_specs(env)\n",
    "out = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2445093bdb356",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = Renderer(env, SEED)\n",
    "renderer.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfe85dc26df794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.generic_policy import MultiAgentPolicy, CombinedPolicy\n",
    "from algorithms.generator import AgentGenerator\n",
    "from algorithms.keys_processors import CombinedExtractor\n",
    "from config import AgentNNConfig, BackboneConfig, HeadConfig, EnvConfig\n",
    "import yaml\n",
    "\n",
    "from config import TrainingConfig, LossConfig\n",
    "from algorithms.simple_nn import TrainableNNAgentPolicy\n",
    "\n",
    "with open(\"configs/run/test_single_training_poachers.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "env_config = EnvConfig.from_dict(config)\n",
    "training_config_attacker = TrainingConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "loss_config_attacker = LossConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "agent_config = AgentNNConfig.from_dict(config)\n",
    "backbone_config = BackboneConfig.from_dict(config, suffix=f\"_backbone\")\n",
    "head_config = HeadConfig.from_dict(config, suffix=f\"_head\")\n",
    "\n",
    "\n",
    "# attacker_agent = MultiAgentPolicy(\n",
    "#     action_size=env.base_env.action_size,\n",
    "#     player_type=1,\n",
    "#     device=\"cpu\",\n",
    "#     embedding_size=32,\n",
    "#     run_name=\"test\",\n",
    "#     policy_generator=AgentGenerator(\n",
    "#         TrainableNNAgentPolicy,\n",
    "#         {\n",
    "#             \"action_size\": env.base_env.action_size,\n",
    "#             \"total_steps\": env.base_env.num_steps,\n",
    "#             \"player_type\": 1,\n",
    "#             \"embedding_size\": 32,\n",
    "#             \"device\": \"cpu\",\n",
    "#             \"loss_config\": loss_config_attacker,\n",
    "#             \"training_config\": training_config_attacker,\n",
    "#             \"run_name\": \"test\",\n",
    "#             \"use_transformer\": True,\n",
    "#         }\n",
    "#     ),\n",
    "# )\n",
    "attacker_extractor = CombinedExtractor(player_type=1, env=env, actions=backbone_config.extractors)\n",
    "attacker_agent = TrainableNNAgentPolicy(\n",
    "    player_type=1,\n",
    "    max_sequence_size=NUM_STEPS + 1,\n",
    "    extractor=attacker_extractor,\n",
    "    action_size=env.action_size,\n",
    "    env_type=env_config.env_pair,\n",
    "    device=\"cpu\",\n",
    "    loss_config=loss_config_attacker,\n",
    "    training_config=training_config_attacker,\n",
    "    run_name=\"test\",\n",
    "    backbone_config=backbone_config,\n",
    "    head_config=head_config,\n",
    "    agent_config=agent_config,\n",
    ")\n",
    "\n",
    "\n",
    "attacker_agent.eval()\n",
    "attacker_agent.load(\"saved_models/2025-07-07_23:54:35-attacker-/attacker/agent_0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e796a534ded8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.generic_policy import RandomAgent, GreedyOraclePoacherAgent\n",
    "\n",
    "\n",
    "greedy_agent = GreedyOraclePoacherAgent(\n",
    "    action_size=env.action_size,\n",
    "    player_type=1,\n",
    "    device=\"cpu\",\n",
    "    run_name=\"test\",\n",
    "    total_steps=NUM_STEPS,\n",
    "    embedding_size=agent_config.embedding_size,\n",
    "    env_map=env_map,\n",
    ")\n",
    "\n",
    "random_agent = RandomAgent(\n",
    "    action_size=env.action_size,\n",
    "    player_type=1,\n",
    "    device=\"cpu\",\n",
    "    run_name=\"test\",\n",
    "    embedding_size=agent_config.embedding_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706f5a5ad5db89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_agent(out)[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb5846c4774c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_agent(out)[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb8e289256c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = attacker_agent(out)\n",
    "a[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dbeeadbf8251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd4f601014d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.update({\n",
    "    \"action\": torch.tensor([4, 5]),\n",
    "})\n",
    "out2 = env.step(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ef19ca2ecf564",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render()\n",
    "out = out2[\"next\"]\n",
    "out[\"game_id\"] = out2[\"game_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efddaef4d2d591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"done\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942313b63ed0fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2[\"next\"][\"available_moves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5dbc8a44b74beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2[\"next\"][\"node_reward_info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222586c9b3eeed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da05671bb0af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out2[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659da01bfb2b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab11057ed167c188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T22:21:04.915125Z",
     "start_time": "2025-08-01T22:21:03.532045Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from algorithms.simple_nn import TrainableNNAgentPolicy, NNAgentPolicy\n",
    "from algorithms.generic_policy import CombinedPolicy, MultiAgentPolicy, ExplorerAgent\n",
    "from algorithms.keys_processors import CombinedExtractor\n",
    "from algorithms.generator import AgentGenerator\n",
    "from config import TrainingConfig, LossConfig, EnvConfig, Player, AgentNNConfig, BackboneConfig, HeadConfig\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "with open(\"configs/run/test_single_training_poachers.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "run_name = \"test\"\n",
    "\n",
    "env_config_ = EnvConfig.from_dict(config)\n",
    "training_config = TrainingConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "loss_config = LossConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "agent_config = AgentNNConfig.from_dict(config)\n",
    "backbone_config = BackboneConfig.from_dict(config, suffix=f\"_backbone\")\n",
    "head_config = HeadConfig.from_dict(config, suffix=f\"_head\")\n",
    "\n",
    "# env_map, env = env_config_.create(\"cpu\")\n",
    "\n",
    "defender_extractor = CombinedExtractor(player_type=0, env=env, actions_map=backbone_config.extractors)\n",
    "attacker_extractor = CombinedExtractor(player_type=1, env=env, actions_map=backbone_config.extractors)\n",
    "\n",
    "defender_agent = NNAgentPolicy(\n",
    "    player_type=0,\n",
    "    max_sequence_size=env_config_.num_steps + 1,\n",
    "    extractor=defender_extractor,\n",
    "    action_size=env.action_size,\n",
    "    backbone_config=backbone_config,\n",
    "    head_config=head_config,\n",
    "    agent_config=agent_config,\n",
    "    device=device,\n",
    "    run_name=run_name,\n",
    ")\n",
    "attacker_agent = TrainableNNAgentPolicy(\n",
    "    player_type=1,\n",
    "    max_sequence_size=env_config_.num_steps + 1,\n",
    "    extractor=attacker_extractor,\n",
    "    action_size=env.action_size,\n",
    "    # env_type=env_config_.env_pair,\n",
    "    device=device,\n",
    "    loss_config=loss_config,\n",
    "    training_config=training_config,\n",
    "    run_name=run_name,\n",
    "    backbone_config=backbone_config,\n",
    "    head_config=head_config,\n",
    "    agent_config=agent_config,\n",
    "    #scheduler_steps=training_config.total_steps_per_turn // training_config.steps_per_batch + 5,\n",
    ")\n",
    "\n",
    "exploration_defender = ExplorerAgent(\n",
    "    action_size=env.action_size,\n",
    "    player_type=0,\n",
    "    device=device,\n",
    "    run_name=run_name,\n",
    "    total_steps=env.num_steps,\n",
    "    embedding_size=agent_config.embedding_size,\n",
    ")\n",
    "exploration_attacker = ExplorerAgent(\n",
    "    action_size=env.action_size,\n",
    "    player_type=1,\n",
    "    device=device,\n",
    "    run_name=run_name,\n",
    "    total_steps=env.num_steps,\n",
    "    embedding_size=agent_config.embedding_size,\n",
    ")\n",
    "combined_policy = CombinedPolicy(\n",
    "    defender_agent,\n",
    "    attacker_agent,\n",
    "    #exploration_defender=exploration_defender,\n",
    "    #exploration_attacker=exploration_attacker,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c7e0a1b7d120a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.steps_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30457014931f6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.collectors import SyncDataCollector, MultiaSyncDataCollector, MultiSyncDataCollector\n",
    "from torchrl.envs import ParallelEnv\n",
    "torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "collector = SyncDataCollector(\n",
    "    #[env.create_from_self for _ in range(4)],\n",
    "    # env.create_from_self,\n",
    "    ParallelEnv(4, env.create_from_self),\n",
    "    policy=combined_policy,\n",
    "    frames_per_batch=3000,\n",
    "    total_frames=3000,\n",
    "    split_trajs=False,\n",
    "    device=\"cpu\",\n",
    "    policy_device=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1825789d19df3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.016482830047607\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "tensordict = next(collector.iterator())\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e51bd4-384b-45b6-8854-37603dce6a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1, -1, -1,  ..., -1, -1,  1],\n",
       "         [-1, -1, -1,  ..., -1, -1, 12]],\n",
       "\n",
       "        [[-1, -1, -1,  ..., -1,  1,  0],\n",
       "         [-1, -1, -1,  ..., -1, 12, 14]],\n",
       "\n",
       "        [[-1, -1, -1,  ...,  1,  0,  1],\n",
       "         [-1, -1, -1,  ..., 12, 14, 12]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1, -1, -1,  ..., -1, 17, 10],\n",
       "         [-1, -1, -1,  ..., -1, 12, 13]],\n",
       "\n",
       "        [[-1, -1, -1,  ..., 17, 10, 12],\n",
       "         [-1, -1, -1,  ..., 12, 13, 14]],\n",
       "\n",
       "        [[-1, -1, -1,  ..., 10, 12, 10],\n",
       "         [-1, -1, -1,  ..., 13, 14, 15]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordict[0][\"position_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0a0095eb00eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict[\"next\"][\"reward\"][:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7caf709b3fa10502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.349676Z",
     "start_time": "2025-08-01T21:15:25.325786Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensordict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtensordict\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mreward\u001b[39m\u001b[33m\"\u001b[39m][:, \u001b[32m1\u001b[39m].max()\n",
      "\u001b[31mNameError\u001b[39m: name 'tensordict' is not defined"
     ]
    }
   ],
   "source": [
    "tensordict[\"next\"][\"reward\"][:, 1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0880bef728f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.351003Z",
     "start_time": "2025-08-01T21:15:25.350797Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "loader = DataLoader([env_map, env_map], batch_size=2)\n",
    "\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e753ee5c3ce8887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.446584Z",
     "start_time": "2025-08-01T21:15:25.421509Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbatch\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b8bb23f20a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6756f25936be7f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.467528Z",
     "start_time": "2025-08-01T21:15:25.464182Z"
    }
   },
   "outputs": [],
   "source": [
    "from unittest.mock import patch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8da15fc0107773",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.484714Z",
     "start_time": "2025-08-01T21:15:25.481031Z"
    }
   },
   "outputs": [],
   "source": [
    "class _Linear(nn.Linear):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        weight_initializer: str | None = None,\n",
    "        bias_initializer: str | None = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_features=in_channels,\n",
    "            out_features=out_channels,\n",
    "            bias=bias,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8e75cfae5804ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.528229Z",
     "start_time": "2025-08-01T21:15:25.493657Z"
    }
   },
   "outputs": [],
   "source": [
    "with patch(\"torch_geometric.nn.conv.gcn_conv.Linear\", side_effect=_Linear):\n",
    "    from torch_geometric.nn.conv import GCNConv\n",
    "    convs = nn.ModuleList([\n",
    "        GCNConv(2, 5, aggr=\"mean\"),\n",
    "        GCNConv(5, 5, aggr=\"mean\"),\n",
    "        GCNConv(5, 5, aggr=\"mean\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcb8b93459b78fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.552873Z",
     "start_time": "2025-08-01T21:15:25.529380Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x = \u001b[43mbatch\u001b[49m.x\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m conv_layer \u001b[38;5;129;01min\u001b[39;00m convs:\n\u001b[32m      3\u001b[39m     x = conv_layer(x, batch.edge_index)\n",
      "\u001b[31mNameError\u001b[39m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "x = batch.x\n",
    "for conv_layer in convs:\n",
    "    x = conv_layer(x, batch.edge_index)\n",
    "    x = torch.relu(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3d60699b0629a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.554103Z",
     "start_time": "2025-08-01T21:15:25.553885Z"
    }
   },
   "outputs": [],
   "source": [
    "from algorithms.generic_policy import MultiAgentPolicy, CombinedPolicy\n",
    "from algorithms.generator import AgentGenerator\n",
    "from algorithms.keys_processors import CombinedExtractor\n",
    "from config import AgentNNConfig, BackboneConfig, HeadConfig, EnvConfig\n",
    "import yaml\n",
    "\n",
    "from config import TrainingConfig, LossConfig\n",
    "from algorithms.simple_nn import TrainableNNAgentPolicy\n",
    "\n",
    "with open(\"configs/run/test_single_training_poachers.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "env_config = EnvConfig.from_dict(config)\n",
    "training_config_attacker = TrainingConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "loss_config_attacker = LossConfig.from_dict(config, suffix=f\"_attacker\")\n",
    "agent_config = AgentNNConfig.from_dict(config)\n",
    "backbone_config = BackboneConfig.from_dict(config, suffix=f\"_backbone\")\n",
    "head_config = HeadConfig.from_dict(config, suffix=f\"_head\")\n",
    "\n",
    "\n",
    "# attacker_agent = MultiAgentPolicy(\n",
    "#     action_size=env.base_env.action_size,\n",
    "#     player_type=1,\n",
    "#     device=\"cpu\",\n",
    "#     embedding_size=32,\n",
    "#     run_name=\"test\",\n",
    "#     policy_generator=AgentGenerator(\n",
    "#         TrainableNNAgentPolicy,\n",
    "#         {\n",
    "#             \"action_size\": env.base_env.action_size,\n",
    "#             \"total_steps\": env.base_env.num_steps,\n",
    "#             \"player_type\": 1,\n",
    "#             \"embedding_size\": 32,\n",
    "#             \"device\": \"cpu\",\n",
    "#             \"loss_config\": loss_config_attacker,\n",
    "#             \"training_config\": training_config_attacker,\n",
    "#             \"run_name\": \"test\",\n",
    "#             \"use_transformer\": True,\n",
    "#         }\n",
    "#     ),\n",
    "# )\n",
    "attacker_extractor = CombinedExtractor(player_type=1, env=env, actions_map=backbone_config.extractors)\n",
    "attacker_agent = TrainableNNAgentPolicy(\n",
    "    player_type=1,\n",
    "    max_sequence_size=NUM_STEPS + 1,\n",
    "    extractor=attacker_extractor,\n",
    "    action_size=env.action_size,\n",
    "    env_type=env_config.env_pair,\n",
    "    device=\"cpu\",\n",
    "    loss_config=loss_config_attacker,\n",
    "    training_config=training_config_attacker,\n",
    "    run_name=\"test\",\n",
    "    backbone_config=backbone_config,\n",
    "    head_config=head_config,\n",
    "    agent_config=agent_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af2b2a92e947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e1e4901a56d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = create_replay_buffer(training_config_attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6d121cf6e323dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.565625Z",
     "start_time": "2025-08-01T21:15:25.558583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1057)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_map.move_cost * (NUM_STEPS - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f1e382d25a51d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.573042Z",
     "start_time": "2025-08-01T21:15:25.567989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5201)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_map.x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "404209e923b28b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.580054Z",
     "start_time": "2025-08-01T21:15:25.576331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6772, -0.1571],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.5329, -0.0349],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.8392, -0.9298],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.6984, -0.4183]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_map.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13dc68e6e7792b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.608401Z",
     "start_time": "2025-08-01T21:15:25.603796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9236)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_map.preparation_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71bb02c647a29393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T21:15:25.634393Z",
     "start_time": "2025-08-01T21:15:25.632593Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
